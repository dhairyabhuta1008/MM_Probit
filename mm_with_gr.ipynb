{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhairyabhuta1008/MM_probit/blob/main/mm_with_gr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e8afa9",
      "metadata": {
        "id": "08e8afa9"
      },
      "outputs": [],
      "source": [
        "from numpy import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from utils import check_for_empty_cols_in_summary, get_zone_output_path\n",
        "import os\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import shortest_path\n",
        "import sys\n",
        "from itertools import combinations\n",
        "import sympy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1caefe5",
      "metadata": {
        "id": "b1caefe5"
      },
      "outputs": [],
      "source": [
        "zone = '500.0'\n",
        "cap_mode = 1                    # 2 for all\n",
        "# cut = -1                      # -1 for no choice\n",
        "# arrival = -1                  # -1 for no choice\n",
        "root = 'data'\n",
        "results_path = 'results/regression'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_zone_output_path(zone, folder):\n",
        "    \"\"\"\n",
        "    Returns the output folder name and output file prefix for a zone\n",
        "    Args:\n",
        "        zone (str): Zone number in float string\n",
        "        folder (str): Root data folder\n",
        "    Returns:\n",
        "        output folder name and output file prefix\n",
        "    \"\"\"\n",
        "    return os.path.join(folder, 'Zones', zone[:-2]), 'Zone_'+zone[:-2] + '_'"
      ],
      "metadata": {
        "id": "RNVF5zHvAQ1s"
      },
      "id": "RNVF5zHvAQ1s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1afd46",
      "metadata": {
        "id": "9b1afd46"
      },
      "outputs": [],
      "source": [
        "def MMfeatures(Location,filename,summary, slotsOffered):\n",
        "    betacoef=[append([0],np.random.rand(len(slotsOffered)+2))]\n",
        "    [featuresleveldf, discountslots, ecoslots]=getActiveFeatures(summary,slotsOffered)\n",
        "    # betadfnew=pd.DataFrame([np.random.rand(len(slotsOffered)+3)], columns=[col+'_Asc' for col in ['NO_PURCHASE']+slotsOffered]+['Discount','Eco'])\n",
        "    betanew=betacoef[0][:]\n",
        "    # colbetaext= [col+'_Asc' for col in ['NO_PURCHASE']+slotsOffered] + discountslots+ecoslots\n",
        "    # betaextdfnew=pd.DataFrame(columns=colbetaext)\n",
        "    betaextnew = formBetaExtNumpy(betanew, len(discountslots), len(ecoslots))\n",
        "    designdf = getDesignMatrix(featuresleveldf.columns.tolist(), slotsOffered)\n",
        "    assortmentdf = summary.loc[:,['C_'+col for col in ['NO_PURCHASE']+slotsOffered]].fillna(0)\n",
        "    choicedf = summary.loc[:,[col for col in ['NO_PURCHASE']+slotsOffered]].fillna(0)\n",
        "    design = designdf.values\n",
        "    featureslevel = featuresleveldf.values\n",
        "    assortment = assortmentdf.values\n",
        "    choice = choicedf.values\n",
        "    i = 0\n",
        "    while True:\n",
        "        i += 1\n",
        "        # pdb.set_trace()\n",
        "        beta=np.copy(betanew)\n",
        "        betaext=np.copy(betaextnew)\n",
        "        [betanew, Q] = updateBetaNumpy(design, featureslevel, discountslots, ecoslots, assortment, choice, betaext, beta, slotsOffered)\n",
        "        loglikeli = sum(log(sum(Q*choice,1)))\n",
        "        betaextnew = formBetaExtNumpy(betanew, len(discountslots), len(ecoslots))\n",
        "        print ('Iteration=',i, 'loglikelihood =',loglikeli, 'beta_disc', betanew[-2], 'beta_eco', betanew[-1])\n",
        "        if np.linalg.norm(betanew-beta)< 10**-6 or i > 500:\n",
        "            predictprobdf = pd.DataFrame(Q,columns=['NO_PURCHASE']+slotsOffered)\n",
        "            betadf = pd.DataFrame([np.array(betanew)], columns=['NO_PURCHASE']+slotsOffered+['Discount', 'Eco'])\n",
        "            predictprobdf.to_csv(Location+filename+'predprobfeatures.csv')\n",
        "            betadf.to_csv(Location+filename+'betafeatures.csv')\n",
        "            del summary, predictprobdf, designdf, featuresleveldf, assortmentdf, choicedf, design, featureslevel, assortment, choice\n",
        "            break\n",
        "    return betadf.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d7281e2",
      "metadata": {
        "id": "5d7281e2"
      },
      "outputs": [],
      "source": [
        "def updateBetaNumpy(design, featureslevel, discountslots, ecoslots, grslots, assortment, choice, betaext, beta, slotsOffered):\n",
        "    #pdb.set_trace()\n",
        "    betanew = np.zeros(len(slotsOffered)+4)\n",
        "    featuresutil = design*betaext ### k*l\n",
        "    utils = featureslevel.dot(featuresutil.T)\n",
        "    exputils = np.exp(utils)*(assortment)\n",
        "    Q = exputils/exputils.sum(axis=1, keepdims=True)\n",
        "\n",
        "    predsharesext = sum(Q.dot(design)*featureslevel, 0)\n",
        "    truesharesext = sum(choice.dot(design)*featureslevel, 0)\n",
        "    #check\n",
        "    trueshare_disc = sum(truesharesext[len(slotsOffered)+1:len(slotsOffered)+1+len(discountslots)])\n",
        "    trueshare_eco = sum(truesharesext[len(slotsOffered)+1+len(discountslots):len(slotsOffered)+1+len(discountslots)+len(ecoslots)])\n",
        "    trueshare_gr = sum(truesharesext[len(slotsOffered)+1+len(discountslots)+len(ecoslots):len(slotsOffered)+1+len(discountslots)+len(ecoslots)+len(grslots)])\n",
        "    #print(\"Trueshare GR\")\n",
        "    #print(trueshare_gr)\n",
        "\n",
        "    predshare_disc = sum(predsharesext[len(slotsOffered)+1:len(slotsOffered)+1+len(discountslots)])\n",
        "    predshare_eco = sum(predsharesext[len(slotsOffered)+1+len(discountslots):len(slotsOffered)+1+len(discountslots)+len(ecoslots)])\n",
        "    predshare_gr = sum(predsharesext[len(slotsOffered)+1+len(discountslots)+len(ecoslots):len(slotsOffered)+1+len(discountslots)+len(ecoslots)+len(grslots)])\n",
        "    #print(\"Predshare GR\")\n",
        "    #print(predshare_gr)\n",
        "\n",
        "    trueshare = np.append(truesharesext[:len(slotsOffered)+1], [trueshare_disc, trueshare_eco, trueshare_gr])\n",
        "    predictshare = np.append(predsharesext[:len(slotsOffered)+1], [predshare_disc, predshare_eco, predshare_gr])\n",
        "    #print(\"Trueshare\")\n",
        "    #print(trueshare)\n",
        "    #print(\"predshare\")\n",
        "    #print(predictshare)\n",
        "    #truseahre\n",
        "    betanew[1:] = beta[1:][:] + np.log(trueshare[1:][:]) - np.log(predictshare[1:][:])\n",
        "    if not discountslots:\n",
        "        betanew[-3] = 0\n",
        "    if not ecoslots:\n",
        "        betanew[-2] = 0\n",
        "    if not grslots:\n",
        "        betanew[-1] = 0\n",
        "    #beta=np.append(beta[:len(slotsOffered)+1]-beta[0],beta[-2:])\n",
        "    return [betanew, Q]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e8986d8",
      "metadata": {
        "id": "6e8986d8"
      },
      "outputs": [],
      "source": [
        "def getLocation(zone, computername):\n",
        "    Location= computername+r'\\\\Zones'+'\\\\'+zone[:-2]+ '\\\\'\n",
        "    Filename= 'Zone_'+zone[:-2]+'_'\n",
        "    return [Location,Filename]\n",
        "\n",
        "#Global Min(non-negative) and max of all the Gr slots and use that as the range.\n",
        "#make global_normalize() after we check this new approach\n",
        "# def normalize(summary, grslots):\n",
        "#     print(\"normalizing\")\n",
        "#     for grslot in grslots:\n",
        "#         if summary[grslot].min() < 0:\n",
        "#             summary[grslot] = (summary[grslot] - summary[grslot].min()) / (summary[grslot].max() - summary[grslot].min())\n",
        "#         else:\n",
        "#             summary[grslot] = summary[grslot] / summary[grslot].max()\n",
        "#         #print(grslot + \" min: \"+ str(summary[grslot].min()) + \" sum: \"+ str(summary[grslot].sum()))\n",
        "\n",
        "def normalize(summary, grslots):\n",
        "    print(\"normalizing\")\n",
        "    max_array = []\n",
        "    min_array = []\n",
        "    for grslot in grslots:\n",
        "        max_array.append(summary[grslot].max())\n",
        "        min_array.append(summary[grslot].min())\n",
        "    max_value = max(max_array)\n",
        "    min_value = min(min_array)\n",
        "    print(max_value)\n",
        "    print(min_value)\n",
        "    for grslot in grslots:\n",
        "        # print(summary[grslot].min())\n",
        "        # print(summary[grslot].max())\n",
        "        # if(summary[grslot].max() == summary[grslot].min()):\n",
        "        #     summary[grslot] = 0\n",
        "        # else:\n",
        "        #     summary[grslot] = (summary[grslot] - summary[grslot].min())\n",
        "        if(max_value == min_value):\n",
        "            summary[grslot] = summary[grslot] / max_value\n",
        "        else:\n",
        "            summary[grslot] = (summary[grslot] - min_value) / (max_value - min_value)\n",
        "        #  for index, row in summary.iterrows():\n",
        "        #     if(row[grslot]<0):\n",
        "        #          summary[grslot][index] = 0\n",
        "        #     else:\n",
        "        #          summary[grslot][index] = 1\n",
        "        # print(summary[grslot])\n",
        "        # print(summary[grslot].min())\n",
        "        # print(summary[grslot].max())\n",
        "        #print(grslot + \" min: \"+ str(summary[grslot].min()) + \" sum: \"+ str(summary[grslot].sum()))\n",
        "\n",
        "def formBetaExt(betadfnew,betaextdfnew):\n",
        "    betaextdfnew[[col for col in betaextdfnew.columns if col.endswith('Asc')]] = betadfnew[[col for col in betadfnew.columns if col.endswith('Asc')]]\n",
        "    betaextdfnew[[col for col in betaextdfnew.columns if col.endswith('Discount')]] = betadfnew['Discount'][0]\n",
        "    betaextdfnew[[col for col in betaextdfnew.columns if col.endswith('Eco')]] = betadfnew['Eco'][0]\n",
        "    return  betaextdfnew\n",
        "\n",
        "\n",
        "def formBetaExtNumpy(beta,len_disc,len_eco, len_gr):\n",
        "    betaext_Asc= beta[0:-3][:]\n",
        "    beta_disc=beta[-3]\n",
        "    beta_eco=beta[-2]\n",
        "    beta_gr=beta[-1]\n",
        "    betaext_disc= beta_disc*np.ones(len_disc)\n",
        "    betaext_eco=beta_eco*np.ones(len_eco)\n",
        "    betaext_gr=beta_gr*np.ones(len_gr)\n",
        "    betaextnew=np.append(betaext_Asc,betaext_disc)\n",
        "    betaextnew=np.append(betaextnew,betaext_eco)\n",
        "    betaextnew=np.append(betaextnew,betaext_gr)\n",
        "    return betaextnew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "867f0b4d",
      "metadata": {
        "id": "867f0b4d"
      },
      "outputs": [],
      "source": [
        "def getActiveFeatures(summary,slotsOffered):\n",
        "    featuresleveldf = summary.loc[:,[col+'_Discount' for col in slotsOffered] + [col+'_Eco' for col in slotsOffered] + [col+'Gr' for col in slotsOffered]]\n",
        "    # this is because gr has +ve and -ve that's why we use != 0\n",
        "    featuresleveldf = featuresleveldf.loc[:, sum(featuresleveldf, 0) != 0]\n",
        "    ecoslots= [col for col in featuresleveldf.columns if col.endswith('Eco')]\n",
        "    discountslots= [col for col in featuresleveldf.columns if col.endswith('Discount')]\n",
        "    grslots= [col for col in featuresleveldf.columns if col.endswith('Gr')]\n",
        "    featuresleveldf=summary.loc[:,discountslots+ecoslots+grslots]\n",
        "    featuresleveldf.loc[:, grslots] += abs(featuresleveldf.loc[:, grslots].min())             # gr value non negative (check)\n",
        "    for i in reversed(['NO_PURCHASE']+slotsOffered):\n",
        "        featuresleveldf.insert(0, i+'_Asc', value=1)\n",
        "    return [featuresleveldf, discountslots, ecoslots, grslots]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9517940",
      "metadata": {
        "id": "f9517940"
      },
      "outputs": [],
      "source": [
        "def getDesignMatrix(featurescolumns, slotsOffered):\n",
        "    '''without no purchase\n",
        "    df=pd.DataFrame(columns=featurescolumns, index=slotsOffered)\n",
        "    for i in slotsOffered:\n",
        "        df.loc[i, [col for col in featurescolumns if i in col]]=1\n",
        "    return df.fillna(0)'''\n",
        "\n",
        "    #with no purchase\n",
        "    df=pd.DataFrame(columns=featurescolumns, index=np.append(['NO_PURCHASE'], slotsOffered))\n",
        "    for i in np.append(['NO_PURCHASE'],slotsOffered):\n",
        "        df.loc[i, [col for col in featurescolumns if i in col]]=1\n",
        "\n",
        "    return df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b775956",
      "metadata": {
        "id": "3b775956"
      },
      "outputs": [],
      "source": [
        "def MMfeaturesBoot(Location, filename, summary, slotsOffered):\n",
        "\n",
        "    # 3 -> beta for disc, eco, Gr , np.append(0) => for NO_PURCHASE\n",
        "\n",
        "    betacoef = [np.append([0], np.random.rand(len(slotsOffered) + 3))]\n",
        "    [featuresleveldf, discountslots, ecoslots, grslots] = getActiveFeatures(summary, slotsOffered)\n",
        "    featuresleveldf.to_csv('featuresleveldf.csv')\n",
        "    normalize(summary, grslots)\n",
        "    betanew = betacoef[0][:]\n",
        "    betaextnew = formBetaExtNumpy(betanew, len(discountslots), len(ecoslots), len(grslots))\n",
        "    designdf = getDesignMatrix(featuresleveldf.columns.tolist(), slotsOffered)\n",
        "\n",
        "    #without no purchase\n",
        "    #which time slot customer had available\n",
        "    #assortmentdf = summary.loc[:, ['C_' + col for col in  slotsFiltered]].fillna(0)\n",
        "    #which time slot customer chooses\n",
        "    #choicedf = summary.loc[:, [col for col in slotsFiltered]].fillna(0)\n",
        "\n",
        "    #with no purchase\n",
        "    assortmentdf = summary.loc[:, ['C' + col for col in ['NO_PURCHASE'] + slotsOffered]].fillna(0)\n",
        "    choicedf = summary.loc[:, [col for col in ['NO_PURCHASE'] + slotsOffered]].fillna(0)\n",
        "\n",
        "    design = designdf.values\n",
        "    featureslevel = featuresleveldf.values\n",
        "    # featureslevel = featureslevel/(3*featureslevel.max())\n",
        "    assortment = assortmentdf.values\n",
        "    choice = choicedf.values\n",
        "\n",
        "    C = np.where(choice == 1)[1]\n",
        "    membership = assortment\n",
        "    nprods = assortment.shape[1]\n",
        "    ## check if the MM algorithm would coverge by testing if the item-item graph\n",
        "    # is strongly connected\n",
        "    row = []\n",
        "    col = []\n",
        "    data = []\n",
        "    for i in range(membership.shape[0]):\n",
        "        assort = list(np.nonzero(membership[i, :])[0])\n",
        "        try:\n",
        "            assort.remove(C[i])\n",
        "        except ValueError:\n",
        "            print (i, C[i], assort)\n",
        "            break\n",
        "        row += len(assort)*[C[i]]\n",
        "        col += assort\n",
        "        data += len(assort)*[1]\n",
        "\n",
        "    dist_matrix = csr_matrix( (data, (row, col)), shape=(nprods, nprods) )\n",
        "    #changed the scipy package\n",
        "    Z = shortest_path(csgraph = dist_matrix, method='D') # Dijkstra's algorithm\n",
        "    I = np.eye(nprods)\n",
        "    if np.count_nonzero(I+Z) < nprods**2:\n",
        "        # condition for convergence of MM algo not met\n",
        "        sys.stderr.write('Warning: Convergence condition for MM algorithm not met...adding noise to the data matrix...\\n')\n",
        "        pairs = [pair for pair in combinations(np.delete(np.arange(nprods),0), 2)]\n",
        "        npairs = len(pairs)\n",
        "        pairs = np.array(pairs)\n",
        "        pairs = np.tile(pairs, (2, 1))\n",
        "        Z = np.zeros((len(pairs), nprods))\n",
        "        for i,pair in enumerate(pairs): Z[i, pair] = 1\n",
        "        assortment = np.vstack((assortment, Z))\n",
        "        d = np.append(pairs[:npairs, 0],pairs[npairs:, 1])\n",
        "        choicenew=np.zeros((Z.shape[0],nprods))\n",
        "        choicenew[np.arange(Z.shape[0]),d] = 1\n",
        "        choice = np.vstack((choice, choicenew))\n",
        "        featuresnew=np.zeros((Z.shape[0], featureslevel.shape[1]))\n",
        "        featuresnew[:, np.arange(nprods)] = 1\n",
        "        featureslevel = np.vstack((featureslevel, featuresnew))\n",
        "    i = 0\n",
        "    while True:\n",
        "        i += 1\n",
        "        # pdb.set_trace()\n",
        "        beta = np.copy(betanew)\n",
        "        betaext = np.copy(betaextnew)\n",
        "        [betanew, Q] = updateBetaNumpy(design, featureslevel, discountslots, ecoslots, grslots, assortment, choice, betaext,\n",
        "                                       beta, slotsOffered)\n",
        "        sum_for_log = sum(Q * choice, 1)\n",
        "        log_of_sum = np.where(sum_for_log != 0, np.log(sum_for_log), 0)\n",
        "        #print(\"sum_for_log: {}\".format(sum_for_log))\n",
        "        #print(\"log of sum: {}\".format(log(sum_for_log)))\n",
        "\n",
        "        loglikeli = sum(log_of_sum)\n",
        "        betaextnew = formBetaExtNumpy(betanew, len(discountslots), len(ecoslots), len(grslots))\n",
        "        print('Iteration=', i, 'loglikelihood =', loglikeli, 'beta_disc', betanew[-3], 'beta_eco', betanew[-2],'beta_gr', betanew[-1] )\n",
        "        print(np.linalg.norm(betanew - beta))\n",
        "        if np.linalg.norm(betanew - beta) < 10 ** -3 or i > 1000:\n",
        "            #without no purchase\n",
        "            #predictprobdf = pd.DataFrame(Q, columns=slotsOffered)\n",
        "            #betadf = pd.DataFrame([np.array(betanew)], columns=slotsOffered + ['Discount', 'Eco', 'Gr'])\n",
        "\n",
        "            #with no purchase\n",
        "            predictprobdf = pd.DataFrame(Q, columns=['NO_PURCHASE'] + slotsOffered)\n",
        "            betadf = pd.DataFrame([np.array(betanew)], columns=['NO_PURCHASE'] + slotsOffered + ['Discount', 'Eco', 'Gr'])\n",
        "            predictprobdf.to_csv(Location + filename + 'predprobfeatures.csv')\n",
        "            betadf.to_csv(Location + filename + 'betafeatures.csv')\n",
        "            del summary, predictprobdf, designdf, featuresleveldf, assortmentdf, choicedf, design, featureslevel, assortment, choice\n",
        "            break\n",
        "    print(\"iteration: {}\".format(i))\n",
        "    print(betadf.shape)\n",
        "    if i == 1001:\n",
        "        return False\n",
        "    return True\n",
        "    #return betadf.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getHourList(zone):\n",
        "    if zone == '500.0':\n",
        "            hourlist={'06:30 - 08:00':'2',\n",
        "           '08:00 - 10:00':'3',\n",
        "           '10:00 - 12:00':'4',\n",
        "           '12:00 - 14:00':'5',\n",
        "           '14:00 - 16:00':'6',\n",
        "           '16:00 - 18:00':'7',\n",
        "           '18:00 - 20:00':'8',\n",
        "           '20:00 - 22:00':'9',\n",
        "           '22:00 - 23:30':'10'}\n",
        "    else:\n",
        "            hourlist={'05:00 - 06:00':'1',\n",
        "           '06:00 - 08:00':'2',\n",
        "           '08:00 - 10:00':'3',\n",
        "           '10:00 - 12:00':'4',\n",
        "           '12:00 - 14:00':'5',\n",
        "           '14:00 - 16:00':'6',\n",
        "           '16:00 - 18:00':'7',\n",
        "           '18:00 - 20:00':'8',\n",
        "           '20:00 - 22:00':'9',\n",
        "           '22:00 - 23:30':'10'}\n",
        "    return hourlist\n",
        "daylist={'2':'1','3':'2','4':'3','5':'4','6':'5','0':'6','1':'7'} # no use"
      ],
      "metadata": {
        "id": "p7aDyc_EAfjk"
      },
      "id": "p7aDyc_EAfjk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    final = []\n",
        "    zone = \"500.0\"\n",
        "    hourlist=getHourList(zone)\n",
        "    slotsOfferedRank=[]\n",
        "    for i in range (1,8):\n",
        "        for j in list(hourlist.values()):\n",
        "                slotsOfferedRank = np.append(slotsOfferedRank,str(i)+'_'+j)\n",
        "    zone_path, zone_file_prefix = get_zone_output_path(zone, root)\n",
        "    summary = pd.read_csv('/content/drive/MyDrive/mm_probit/results/new_gr/simulation/500.0/gr_unranked_stacked_1500_arrival_0_cut_0_cap_0.csv')\n",
        "    #summary = summary.drop(['NO_PURCHASE_Eco', 'NO_PURCHASE_Discount', 'NO_PURCHASEGr'], axis=1)\n",
        "    slots_active = ['0_06:30 - 08:00','0_08:00 - 10:00','0_10:00 - 12:00','0_12:00 - 14:00', '0_14:00 - 16:00', '0_16:00 - 18:00', '0_18:00 - 20:00', '0_20:00 - 22:00', '0_22:00 - 23:30', '1_06:30 - 08:00', '1_08:00 - 10:00', '1_10:00 - 12:00', '1_12:00 - 14:00', '1_14:00 - 16:00', '1_16:00 - 18:00', '1_18:00 - 20:00', '1_20:00 - 22:00', '1_22:00 - 23:30', '2_06:30 - 08:00', '2_08:00 - 10:00', '2_10:00 - 12:00', '2_12:00 - 14:00', '2_14:00 - 16:00', '2_16:00 - 18:00', '2_18:00 - 20:00', '2_20:00 - 22:00', '2_22:00 - 23:30', '3_06:30 - 08:00', '3_08:00 - 10:00', '3_10:00 - 12:00', '3_12:00 - 14:00', '3_14:00 - 16:00', '3_16:00 - 18:00', '3_18:00 - 20:00', '3_20:00 - 22:00', '3_22:00 - 23:30', '4_06:30 - 08:00', '4_08:00 - 10:00', '4_10:00 - 12:00', '4_12:00 - 14:00', '4_14:00 - 16:00', '4_16:00 - 18:00', '4_18:00 - 20:00', '4_20:00 - 22:00', '4_22:00 - 23:30', '5_06:30 - 08:00', '5_08:00 - 10:00', '5_10:00 - 12:00', '5_12:00 - 14:00', '5_14:00 - 16:00', '5_16:00 - 18:00', '5_18:00 - 20:00', '5_20:00 - 22:00', '5_22:00 - 23:30', '6_06:30 - 08:00', '6_08:00 - 10:00', '6_10:00 - 12:00', '6_12:00 - 14:00', '6_14:00 - 16:00', '6_16:00 - 18:00', '6_18:00 - 20:00', '6_20:00 - 22:00', '6_22:00 - 23:30']\n",
        "    slots_active_filtered = []\n",
        "    for slot in slotsOfferedRank:\n",
        "        sum_of_all_rows = summary[slot].sum()\n",
        "        if sum_of_all_rows > 0:\n",
        "            slots_active_filtered.append(slot)\n",
        "            try:\n",
        "                summary[slot+'_Discount']\n",
        "            except:\n",
        "                summary[slot+'_Discount'] = 0\n",
        "    print(len(slots_active_filtered))\n",
        "    print(slots_active_filtered)\n",
        "    MMfeaturesBoot(zone_path, zone_file_prefix, summary, slots_active_filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "4cHwTajRAgaS",
        "outputId": "b0752da4-e757-47e5-aba2-5b272fcac5a5"
      },
      "id": "4cHwTajRAgaS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63\n",
            "['1_2', '1_3', '1_4', '1_5', '1_6', '1_7', '1_8', '1_9', '1_10', '2_2', '2_3', '2_4', '2_5', '2_6', '2_7', '2_8', '2_9', '2_10', '3_2', '3_3', '3_4', '3_5', '3_6', '3_7', '3_8', '3_9', '3_10', '4_2', '4_3', '4_4', '4_5', '4_6', '4_7', '4_8', '4_9', '4_10', '5_2', '5_3', '5_4', '5_5', '5_6', '5_7', '5_8', '5_9', '5_10', '6_2', '6_3', '6_4', '6_5', '6_6', '6_7', '6_8', '6_9', '6_10', '7_2', '7_3', '7_4', '7_5', '7_6', '7_7', '7_8', '7_9', '7_10']\n",
            "normalizing\n",
            "0.5210358314818356\n",
            "-4.408548975262699\n",
            "Iteration= 1 loglikelihood = nan beta_disc nan beta_eco nan beta_gr nan\n",
            "nan\n",
            "Iteration= 2 loglikelihood = nan beta_disc nan beta_eco nan beta_gr nan\n",
            "nan\n",
            "Iteration= 3 loglikelihood = nan beta_disc nan beta_eco nan beta_gr nan\n",
            "nan\n",
            "Iteration= 4 loglikelihood = nan beta_disc nan beta_eco nan beta_gr nan\n",
            "nan\n",
            "Iteration= 5 loglikelihood = nan beta_disc nan beta_eco nan beta_gr nan\n",
            "nan\n",
            "Iteration= 6 loglikelihood = nan beta_disc nan beta_eco nan beta_gr nan\n",
            "nan\n",
            "Iteration= 7 loglikelihood = nan beta_disc nan beta_eco nan beta_gr nan\n",
            "nan\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e57f9f81efa0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslots_active_filtered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslots_active_filtered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mMMfeaturesBoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzone_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzone_file_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslots_active_filtered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-8749d4d65ece>\u001b[0m in \u001b[0;36mMMfeaturesBoot\u001b[0;34m(Location, filename, summary, slotsOffered)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetanew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mbetaext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetaextnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         [betanew, Q] = updateBetaNumpy(design, featureslevel, discountslots, ecoslots, grslots, assortment, choice, betaext,\n\u001b[0m\u001b[1;32m     76\u001b[0m                                        beta, slotsOffered)\n\u001b[1;32m     77\u001b[0m         \u001b[0msum_for_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-c6681b70dc6a>\u001b[0m in \u001b[0;36mupdateBetaNumpy\u001b[0;34m(design, featureslevel, discountslots, ecoslots, grslots, assortment, choice, betaext, beta, slotsOffered)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbetanew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslotsOffered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfeaturesutil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesign\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbetaext\u001b[0m \u001b[0;31m### k*l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mutils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureslevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mexputils\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massortment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexputils\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mexputils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13074821",
      "metadata": {
        "id": "13074821"
      },
      "outputs": [],
      "source": [
        "#gr_df = pd.read_csv('gr_disc_35.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn2Phl99Ajk2",
        "outputId": "a3afd6b9-9fcd-4340-c6d0-24a23d6e56b0"
      },
      "id": "Zn2Phl99Ajk2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "711d8814",
      "metadata": {
        "id": "711d8814"
      },
      "outputs": [],
      "source": [
        "# slots_active = []\n",
        "# for col in gr_df.columns:\n",
        "#     if col.endswith('Gr'):\n",
        "#         slots_active.append(col[:-2])\n",
        "# print(slots_active)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ff3d2a",
      "metadata": {
        "id": "c4ff3d2a"
      },
      "outputs": [],
      "source": [
        "#put grs and disc to zero\n",
        "def modify_summary(df, non_zero_slot):\n",
        "    for col in df.columns:\n",
        "        if col != non_zero_slot:\n",
        "            zero_gr_col = col+'Gr'\n",
        "            if zero_gr_col in df.columns:\n",
        "                df[zero_gr_col].values[:] = 0\n",
        "    return df\n",
        "\n",
        "def modify_summary_incremental(df, non_zero_slots):\n",
        "    for col in df.columns:\n",
        "        if col.endswith('Gr') and col not in non_zero_slots:\n",
        "            df[col].values[:] = 0\n",
        "    return df\n",
        "\n",
        "def check_summary(df):\n",
        "    print(\"checking summary\")\n",
        "    for col in df.columns:\n",
        "        if col.endswith('Gr'):\n",
        "            if df[col].sum() != 0:\n",
        "               print(\"non_zero_gr_col: \" + col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74072205",
      "metadata": {
        "id": "74072205",
        "outputId": "57ba3af2-357b-405c-9334-7db55c9b1e41"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'0_06:30 - 08:00'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3652\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3653\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '0_06:30 - 08:00'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/jp/jrk1ttw17xj8hj7ndvq249yr0000gn/T/ipykernel_58321/1560928617.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mslot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslots_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(slot +  \" sum of all rows: \" + str( summary[slot].sum() ) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msum_of_all_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msum_of_all_rows\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mslots_active_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3653\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3654\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3655\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '0_06:30 - 08:00'"
          ]
        }
      ],
      "source": [
        "## TODO: 1 probit on all columns at once, instead of separately with minimum Discount >= 35\n",
        "## 2) Plain MM every arrival day before cut1 and before cut2 without Gr and with Gr\n",
        "## 3) for each arrival day and for each cap_mode_choice for both zone 500,700\n",
        "## 4) Bootstrap for standard errors (refer Fresh Direct notebook for details)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    zone_path, zone_file_prefix = get_zone_output_path(zone, root)\n",
        "    #summary = pd.read_csv('/Users/anupamtripathi/PycharmProjects/RA_/results/gr/500.0/gr_unranked_stacked_arrival_0_cut_0_cap_2.csv')\n",
        "    summary = pd.read_csv('gr_unranked_stacked_1500_arrival_0_cut_0_cap_0 (1).csv')\n",
        "    #summary = pd.read_csv('/Users/sathvik/Desktop/RA/RA_/results/gr/active_all_slots/without_no_purchase/700.0/gr_unranked_stacked_arrival_0_cut_1_cap_0.csv')\n",
        "    #summary = summary.drop(['NO_PURCHASE_Eco', 'NO_PURCHASE_Discount'], axis=1)\n",
        "    summary = summary.fillna(0)\n",
        "    # for col in summary.columns:\n",
        "    #     print(col)\n",
        "    # double checking slots_active is correctly calculated\n",
        "    slots_active_filtered = []\n",
        "    slots_active = ['0_06:30 - 08:00','0_08:00 - 10:00','0_10:00 - 12:00','0_12:00 - 14:00', '0_14:00 - 16:00', '0_16:00 - 18:00', '0_18:00 - 20:00', '0_20:00 - 22:00', '0_22:00 - 23:30', '1_06:30 - 08:00', '1_08:00 - 10:00', '1_10:00 - 12:00', '1_12:00 - 14:00', '1_14:00 - 16:00', '1_16:00 - 18:00', '1_18:00 - 20:00', '1_20:00 - 22:00', '1_22:00 - 23:30', '2_06:30 - 08:00', '2_08:00 - 10:00', '2_10:00 - 12:00', '2_12:00 - 14:00', '2_14:00 - 16:00', '2_16:00 - 18:00', '2_18:00 - 20:00', '2_20:00 - 22:00', '2_22:00 - 23:30', '3_06:30 - 08:00', '3_08:00 - 10:00', '3_10:00 - 12:00', '3_12:00 - 14:00', '3_14:00 - 16:00', '3_16:00 - 18:00', '3_18:00 - 20:00', '3_20:00 - 22:00', '3_22:00 - 23:30', '4_06:30 - 08:00', '4_08:00 - 10:00', '4_10:00 - 12:00', '4_12:00 - 14:00', '4_14:00 - 16:00', '4_16:00 - 18:00', '4_18:00 - 20:00', '4_20:00 - 22:00', '4_22:00 - 23:30', '5_06:30 - 08:00', '5_08:00 - 10:00', '5_10:00 - 12:00', '5_12:00 - 14:00', '5_14:00 - 16:00', '5_16:00 - 18:00', '5_18:00 - 20:00', '5_20:00 - 22:00', '5_22:00 - 23:30', '6_06:30 - 08:00', '6_08:00 - 10:00', '6_10:00 - 12:00', '6_12:00 - 14:00', '6_14:00 - 16:00', '6_16:00 - 18:00', '6_18:00 - 20:00', '6_20:00 - 22:00', '6_22:00 - 23:30']\n",
        "    for slot in slots_active:\n",
        "        #print(slot +  \" sum of all rows: \" + str( summary[slot].sum() ) )\n",
        "        sum_of_all_rows = summary[slot].sum()\n",
        "        if sum_of_all_rows > 0:\n",
        "            slots_active_filtered.append(slot)\n",
        "    slots_active_filtered_again=[]\n",
        "    for slot in slots_active_filtered:\n",
        "        if slot+'Gr' in summary.columns:\n",
        "            slots_active_filtered_again.append(slot)\n",
        "    MMfeaturesBoot(zone_path, zone_file_prefix, summary, slots_active_filtered_again)\n",
        "\n",
        "    slot_to_convergence_map = {}\n",
        "    for slot in slots_active_filtered_again:\n",
        "        new_summary = summary.copy()\n",
        "        new_summary = modify_summary(new_summary, slot)\n",
        "        check_summary(new_summary)\n",
        "        slot_to_convergence_map[slot] = MMfeaturesBoot(zone_path, zone_file_prefix, new_summary, slots_active_filtered_again)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "070ded8e",
      "metadata": {
        "id": "070ded8e",
        "outputId": "2c3e6bc4-7e6d-45db-804e-54cefa17963e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0_06:30 - 08:00': False,\n",
              " '0_08:00 - 10:00': False,\n",
              " '0_10:00 - 12:00': False,\n",
              " '0_12:00 - 14:00': False,\n",
              " '0_14:00 - 16:00': False,\n",
              " '0_16:00 - 18:00': False,\n",
              " '0_18:00 - 20:00': False,\n",
              " '0_20:00 - 22:00': False,\n",
              " '0_22:00 - 23:30': True,\n",
              " '1_06:30 - 08:00': True,\n",
              " '1_08:00 - 10:00': True,\n",
              " '1_10:00 - 12:00': False,\n",
              " '1_12:00 - 14:00': True,\n",
              " '1_14:00 - 16:00': True,\n",
              " '1_16:00 - 18:00': False,\n",
              " '1_18:00 - 20:00': True,\n",
              " '1_20:00 - 22:00': True,\n",
              " '1_22:00 - 23:30': False,\n",
              " '2_06:30 - 08:00': True,\n",
              " '2_08:00 - 10:00': True,\n",
              " '2_10:00 - 12:00': True,\n",
              " '2_12:00 - 14:00': False,\n",
              " '2_14:00 - 16:00': True,\n",
              " '2_16:00 - 18:00': True,\n",
              " '2_18:00 - 20:00': True,\n",
              " '2_20:00 - 22:00': True,\n",
              " '2_22:00 - 23:30': True,\n",
              " '3_06:30 - 08:00': False,\n",
              " '3_08:00 - 10:00': False,\n",
              " '3_10:00 - 12:00': False,\n",
              " '3_12:00 - 14:00': True,\n",
              " '3_14:00 - 16:00': False,\n",
              " '3_16:00 - 18:00': False,\n",
              " '3_18:00 - 20:00': False,\n",
              " '3_20:00 - 22:00': True,\n",
              " '3_22:00 - 23:30': True,\n",
              " '4_06:30 - 08:00': False,\n",
              " '4_08:00 - 10:00': False,\n",
              " '4_10:00 - 12:00': False,\n",
              " '4_12:00 - 14:00': True,\n",
              " '4_14:00 - 16:00': False,\n",
              " '4_16:00 - 18:00': False,\n",
              " '4_18:00 - 20:00': False,\n",
              " '4_20:00 - 22:00': False,\n",
              " '4_22:00 - 23:30': True,\n",
              " '5_06:30 - 08:00': True,\n",
              " '5_08:00 - 10:00': False,\n",
              " '5_10:00 - 12:00': False,\n",
              " '5_12:00 - 14:00': False,\n",
              " '5_14:00 - 16:00': False,\n",
              " '5_16:00 - 18:00': False,\n",
              " '5_18:00 - 20:00': False,\n",
              " '5_20:00 - 22:00': False,\n",
              " '6_06:30 - 08:00': False,\n",
              " '6_08:00 - 10:00': False,\n",
              " '6_10:00 - 12:00': False,\n",
              " '6_12:00 - 14:00': False,\n",
              " '6_14:00 - 16:00': False,\n",
              " '6_16:00 - 18:00': False,\n",
              " '6_18:00 - 20:00': False,\n",
              " '6_20:00 - 22:00': False,\n",
              " '6_22:00 - 23:30': False}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slot_to_convergence_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc220e4",
      "metadata": {
        "id": "1cc220e4"
      },
      "outputs": [],
      "source": [
        "slot_to_convergence_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6972b8f2",
      "metadata": {
        "id": "6972b8f2"
      },
      "outputs": [],
      "source": [
        "coverging_slots = []\n",
        "non_converging_slots = []\n",
        "for k,v in slot_to_convergence_map.items():\n",
        "    if v == True:\n",
        "        coverging_slots.append(k)\n",
        "    else:\n",
        "        non_converging_slots.append(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e565208",
      "metadata": {
        "id": "0e565208"
      },
      "outputs": [],
      "source": [
        "coverging_slots = [slot+'Gr' for slot in coverging_slots]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed0563d",
      "metadata": {
        "id": "eed0563d"
      },
      "outputs": [],
      "source": [
        "zone_path, zone_file_prefix = get_zone_output_path(zone, root)\n",
        "#summary = pd.read_csv('/Users/anupamtripathi/PycharmProjects/RA_/results/gr/500.0/gr_unranked_stacked_arrival_0_cut_0_cap_2.csv')\n",
        "summary = pd.read_csv('results/gr/700.0/gr_unranked_stacked_arrival_0_cut_0_cap_0.csv')\n",
        "#summary = pd.read_csv('/Users/sathvik/Desktop/RA/RA_/results/gr/active_all_slots/without_no_purchase/700.0/gr_unranked_stacked_arrival_0_cut_1_cap_0.csv')\n",
        "summary = summary.drop(['NO_PURCHASE_Eco', 'NO_PURCHASE_Discount'], axis=1)\n",
        "summary = summary.fillna(0)\n",
        "\n",
        " # double checking slots_active is correctly calculated\n",
        "slots_active_filtered = []\n",
        "for slot in slots_active:\n",
        "    #print(slot +  \" sum of all rows: \" + str( summary[slot].sum() ) )\n",
        "    sum_of_all_rows = summary[slot].sum()\n",
        "    if sum_of_all_rows > 0:\n",
        "        slots_active_filtered.append(slot)\n",
        "\n",
        "non_zero_gr_cols = []\n",
        "zero_gr_cols = coverging_slots\n",
        "non_zero_gr_cols.append(zero_gr_cols.pop(0))\n",
        "\n",
        "slots_increment_conveging_map  = {}\n",
        "while len(non_zero_gr_cols) != 0 and len(zero_gr_cols) != 0:\n",
        "    new_summary = summary.copy()\n",
        "    new_summary = modify_summary_incremental(new_summary, non_zero_gr_cols)\n",
        "    check_summary(new_summary)\n",
        "    #print(non_zero_gr_cols)\n",
        "    non_zero_gr_cols.append(zero_gr_cols.pop(0))\n",
        "    non_zero_gr_cols_str = ('_').join(non_zero_gr_cols)\n",
        "    slots_increment_conveging_map[non_zero_gr_cols_str] = MMfeaturesBoot(zone_path, zone_file_prefix, new_summary, slots_active_filtered)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b4ba78",
      "metadata": {
        "id": "44b4ba78"
      },
      "outputs": [],
      "source": [
        "# 5/3 - Tues\n",
        "# TODO\n",
        "# 1) Split the slots as converging and non-converging gr slots\n",
        "# 2) Keep incrementally adding only converging slots and see overall convergence\n",
        "# 3) try analyze properties of non-converging time slots\n",
        "# 4) check linear dependence between gr cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17e52139",
      "metadata": {
        "id": "17e52139"
      },
      "outputs": [],
      "source": [
        "slots_increment_conveging_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb788b6",
      "metadata": {
        "id": "fcb788b6"
      },
      "outputs": [],
      "source": [
        "non_converging_gr_slots = [slot+'Gr' for slot in non_converging_slots]\n",
        "summary_non_converging_gr_slots = summary[non_converging_gr_slots]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25b344eb",
      "metadata": {
        "id": "25b344eb"
      },
      "outputs": [],
      "source": [
        "non_gr_summary = summary_non_converging_gr_slots.describe()\n",
        "non_gr_summary.to_csv('non_gr_summary.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b5b8b96",
      "metadata": {
        "id": "7b5b8b96"
      },
      "outputs": [],
      "source": [
        "corrrelation    = summary_non_converging_gr_slots.corr(method=\"pearson\");\n",
        "print(\"Pearson correlation coefficient:\");\n",
        "print(corrrelation);\n",
        "corrrelation.to_csv(\"pearson.csv\")\n",
        "plt.figure(figsize = (15,8))\n",
        "sns.heatmap(corrrelation,cmap=\"YlGnBu\")\n",
        "plt.savefig('pearson_heatmap.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "563512b1",
      "metadata": {
        "id": "563512b1"
      },
      "outputs": [],
      "source": [
        "corrrelation    = summary_non_converging_gr_slots.corr(method=\"spearman\");\n",
        "print(\"Spearman rank correlation:\");\n",
        "corrrelation.to_csv(\"spearman.csv\")\n",
        "sns.heatmap(corrrelation,cmap=\"YlGnBu\")\n",
        "print(corrrelation);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924a0478",
      "metadata": {
        "id": "924a0478"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}